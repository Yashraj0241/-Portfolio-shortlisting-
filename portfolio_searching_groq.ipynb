{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b199a59c-eefa-4f72-a1c8-4a13abeedc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script distro.exe is installed in 'C:\\Users\\pavan\\anaconda\\envs\\llm_env\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script langsmith.exe is installed in 'C:\\Users\\pavan\\anaconda\\envs\\llm_env\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.0.200 requires pydantic<2,>=1, but you have pydantic 2.10.1 which is incompatible.\n",
      "langchainplus-sdk 0.0.20 requires pydantic<2,>=1, but you have pydantic 2.10.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# %pip install -qU langchain-groq           commented bcz its already installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4568a9a-d949-4e68-a98d-52a35b4bb0b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticUserError",
     "evalue": "If you use `@root_validator` with pre=False (the default) you MUST specify `skip_on_failure=True`. Note that `@root_validator` is deprecated and should be replaced with `@model_validator`.\n\nFor further information visit https://errors.pydantic.dev/2.10/u/root-validator-pre-skip",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPydanticUserError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_groq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatGroq\n\u001b[1;32m----> 3\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mChatGroq\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama-3.1-70b-versatile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgsk_0GKFfePcvZGVheIS1MBcWGdyb3FYX4NixvxqI2v2dXMzKuPJXNTD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# other params...\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda\\envs\\llm_env\\lib\\site-packages\\langchain_core\\load\\serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda\\envs\\llm_env\\lib\\site-packages\\langchain_core\\language_models\\base.py:92\u001b[0m, in \u001b[0;36m_get_verbosity\u001b[1;34m()\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_verbosity\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglobals\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_verbose\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_verbose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda\\envs\\llm_env\\lib\\site-packages\\langchain_core\\globals.py:59\u001b[0m, in \u001b[0;36mget_verbose\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the value of the `verbose` global setting.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m    The value of the `verbose` global setting.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# We're about to run some deprecated code, don't report warnings from it.\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# The user called the correct (non-deprecated) code path and shouldn't get warnings.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n",
      "File \u001b[1;32m~\\anaconda\\envs\\llm_env\\lib\\site-packages\\langchain\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metadata\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MRKLChain, ReActChain, SelfAskWithSearchChain\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseCache\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     ConversationChain,\n\u001b[0;32m     10\u001b[0m     LLMBashChain,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     VectorDBQAWithSourcesChain,\n\u001b[0;32m     19\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda\\envs\\llm_env\\lib\\site-packages\\langchain\\agents\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Interface for agents.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     Agent,\n\u001b[0;32m      4\u001b[0m     AgentExecutor,\n\u001b[0;32m      5\u001b[0m     AgentOutputParser,\n\u001b[0;32m      6\u001b[0m     BaseMultiActionAgent,\n\u001b[0;32m      7\u001b[0m     BaseSingleActionAgent,\n\u001b[0;32m      8\u001b[0m     LLMSingleActionAgent,\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent_toolkits\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     create_csv_agent,\n\u001b[0;32m     12\u001b[0m     create_json_agent,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     create_vectorstore_router_agent,\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AgentType\n",
      "File \u001b[1;32m~\\anaconda\\envs\\llm_env\\lib\\site-packages\\langchain\\agents\\agent.py:16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel, root_validator\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AgentType\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InvalidTool\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_language\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseLanguageModel\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseCallbackManager\n",
      "File \u001b[1;32m~\\anaconda\\envs\\llm_env\\lib\\site-packages\\langchain\\agents\\tools.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Interface for tools.\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     AsyncCallbackManagerForToolRun,\n\u001b[0;32m      6\u001b[0m     CallbackManagerForToolRun,\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseTool, Tool, tool\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mInvalidTool\u001b[39;00m(BaseTool):\n",
      "File \u001b[1;32m~\\anaconda\\envs\\llm_env\\lib\\site-packages\\langchain\\callbacks\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Callback handlers that allow listening to events in LangChain.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maim_callback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AimCallbackHandler\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01margilla_callback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArgillaCallbackHandler\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclearml_callback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClearMLCallbackHandler\n",
      "File \u001b[1;32m~\\anaconda\\envs\\llm_env\\lib\\site-packages\\langchain\\callbacks\\aim_callback.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepcopy\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Optional, Union\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseCallbackHandler\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AgentAction, AgentFinish, LLMResult\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimport_aim\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "File \u001b[1;32m~\\anaconda\\envs\\llm_env\\lib\\site-packages\\langchain\\callbacks\\base.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Optional, Union\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01muuid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UUID\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     AgentAction,\n\u001b[0;32m      9\u001b[0m     AgentFinish,\n\u001b[0;32m     10\u001b[0m     BaseMessage,\n\u001b[0;32m     11\u001b[0m     LLMResult,\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLLMManagerMixin\u001b[39;00m:\n\u001b[0;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mixin for LLM callbacks.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda\\envs\\llm_env\\lib\\site-packages\\langchain\\schema.py:169\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmessages_from_dict\u001b[39m(messages: List[\u001b[38;5;28mdict\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[BaseMessage]:\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_message_from_dict(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages]\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mChatGeneration\u001b[39;00m(Generation):\n\u001b[0;32m    170\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Output of a single generation.\"\"\"\u001b[39;00m\n\u001b[0;32m    172\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda\\envs\\llm_env\\lib\\site-packages\\langchain\\schema.py:176\u001b[0m, in \u001b[0;36mChatGeneration\u001b[1;34m()\u001b[0m\n\u001b[0;32m    172\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    173\u001b[0m message: BaseMessage\n\u001b[0;32m    175\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;129;43m@root_validator\u001b[39;49m\n\u001b[1;32m--> 176\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mset_text\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mDict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAny\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAny\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda\\envs\\llm_env\\lib\\site-packages\\pydantic\\deprecated\\class_validators.py:234\u001b[0m, in \u001b[0;36mroot_validator\u001b[1;34m(pre, skip_on_failure, allow_reuse, *__args)\u001b[0m\n\u001b[0;32m    224\u001b[0m warn(\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPydantic V1 style `@root_validator` validators are deprecated.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m You should migrate to Pydantic V2 style `@model_validator` validators,\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    229\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    230\u001b[0m )\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m __args:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;66;03m# Ensure a nice error is raised if someone attempts to use the bare decorator\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mroot_validator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m(\u001b[38;5;241m*\u001b[39m__args)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_reuse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m    237\u001b[0m     warn(_ALLOW_REUSE_WARNING_MESSAGE, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda\\envs\\llm_env\\lib\\site-packages\\pydantic\\deprecated\\class_validators.py:240\u001b[0m, in \u001b[0;36mroot_validator\u001b[1;34m(pre, skip_on_failure, allow_reuse, *__args)\u001b[0m\n\u001b[0;32m    238\u001b[0m mode: Literal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pre \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m skip_on_failure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 240\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you use `@root_validator` with pre=False (the default) you MUST specify `skip_on_failure=True`.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    242\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Note that `@root_validator` is deprecated and should be replaced with `@model_validator`.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    243\u001b[0m         code\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroot-validator-pre-skip\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    244\u001b[0m     )\n\u001b[0;32m    246\u001b[0m wrap \u001b[38;5;241m=\u001b[39m partial(_decorators_v1\u001b[38;5;241m.\u001b[39mmake_v1_generic_root_validator, pre\u001b[38;5;241m=\u001b[39mpre)\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdec\u001b[39m(f: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mclassmethod\u001b[39m[Any, Any, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstaticmethod\u001b[39m[Any, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "\u001b[1;31mPydanticUserError\u001b[0m: If you use `@root_validator` with pre=False (the default) you MUST specify `skip_on_failure=True`. Note that `@root_validator` is deprecated and should be replaced with `@model_validator`.\n\nFor further information visit https://errors.pydantic.dev/2.10/u/root-validator-pre-skip"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-70b-versatile\",        # groq model\n",
    "    temperature=0.5,                        # it's mention randomness in result after maximum times asking\n",
    "    max_tokens=None,                        # unit of words you wants to generate , here none means the generate no. of words like upto your limitations \n",
    "    timeout=None,                           # maximum time to wait for the model responce\n",
    "    max_retries=2,                          # no. of attempts , after 2 attempts its gives error bcz here limitation is 2\n",
    "    api_key=\"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\" # this ensures that only authorised user can interact with the groq language model\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6add3c3-51c3-4021-9bc4-9a31c1486c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (0.0.200)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.8-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from langchain) (0.3.21)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from langchain) (0.1.145)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from langchain) (2.10.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain) (3.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.0)\n",
      "Downloading langchain-0.3.8-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 15.8 MB/s eta 0:00:00\n",
      "Downloading langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: langchain-text-splitters, langchain\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.0.200\n",
      "    Uninstalling langchain-0.0.200:\n",
      "      Successfully uninstalled langchain-0.0.200\n",
      "Successfully installed langchain-0.3.8 langchain-text-splitters-0.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script langchain-server.exe is installed in 'C:\\Users\\pavan\\anaconda\\envs\\llm_env\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "# pip install --upgrade langchain                              installed\n",
    "                                # langchain is a framework of llm models like(OpenAI , Google Bard , meta ,whisper models like that) \n",
    "                                # that provides tools , libraries , and integration to developer to easily combine llm model with data source or api's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "494b215f-35be-40a4-81c8-e497b76eaa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    temperature=0.5,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    api_key=\"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\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b60bfb0e-b555-493d-88b9-02f57ed3d711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm not a doctor, but I can provide some general information about common over-the-counter (OTC) medications that may help alleviate stomach ache. However, please consult a healthcare professional for a proper diagnosis and treatment plan.\\n\\nThat being said, here are some common OTC medications that may help with stomach ache:\\n\\n1. **Antacids**:\\n\\t* Tums (Calcium carbonate)\\n\\t* Rolaids (Magnesium hydroxide and aluminum hydroxide)\\n\\t* Mylanta (Aluminum hydroxide and magnesium hydroxide)\\n\\t* These medications can help neutralize stomach acid and provide quick relief from heartburn and indigestion.\\n2. **Histamine-2 (H2) blockers**:\\n\\t* Ranitidine (Zantac)\\n\\t* Famotidine (Pepcid)\\n\\t* These medications can help reduce acid production in the stomach and alleviate symptoms of heartburn and indigestion.\\n3. **Proton pump inhibitors (PPIs)**:\\n\\t* Omeprazole (Prilosec)\\n\\t* Lansoprazole (Prevacid)\\n\\t* These medications can help block the production of stomach acid and provide longer-term relief from heartburn and indigestion.\\n4. **Anti-diarrheal medications**:\\n\\t* Loperamide (Imodium)\\n\\t* Bismuth subsalicylate (Pepto-Bismol)\\n\\t* These medications can help slow down bowel movements and alleviate symptoms of diarrhea.\\n5. **Pain relievers**:\\n\\t* Acetaminophen (Tylenol)\\n\\t* Ibuprofen (Advil, Motrin)\\n\\t* These medications can help alleviate stomach pain and discomfort, but be sure to follow the recommended dosage and consult a healthcare professional if you have any underlying medical conditions.\\n\\nRemember to always read and follow the label instructions, and consult a healthcare professional if:\\n\\n* Your symptoms persist or worsen\\n* You experience severe abdominal pain, vomiting, or bleeding\\n* You have a history of stomach ulcers, kidney disease, or other underlying medical conditions\\n* You are taking prescription medications or have allergies\\n\\nPlease consult a healthcare professional for a proper diagnosis and treatment plan.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 451, 'prompt_tokens': 53, 'total_tokens': 504, 'completion_time': 1.804, 'prompt_time': 0.009557438, 'queue_time': 0.005800249, 'total_time': 1.8135574380000001}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_5c5d1b5cfb', 'finish_reason': 'stop', 'logprobs': None}, id='run-edb3b5e9-2c53-4193-bdfc-364fe814e829-0', usage_metadata={'input_tokens': 53, 'output_tokens': 451, 'total_tokens': 504})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"you are help to solve medicine issues\",\n",
    "    ),\n",
    "    (\"human\", \"I have stomach ache .Suggest me some medicines.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)     # invoke function in LLM api (such as langchain) is used for to send input msg to llm model and take responce from that\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9326c93b-b22a-4d2e-a62c-fd851b3fd3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not a doctor, but I can provide some general information about common over-the-counter (OTC) medications that may help alleviate stomach ache. However, please consult a healthcare professional for a proper diagnosis and treatment plan.\n",
      "\n",
      "That being said, here are some common OTC medications that may help with stomach ache:\n",
      "\n",
      "1. **Antacids**:\n",
      "\t* Tums (Calcium carbonate)\n",
      "\t* Rolaids (Magnesium hydroxide and aluminum hydroxide)\n",
      "\t* Mylanta (Aluminum hydroxide and magnesium hydroxide)\n",
      "\t* These medications can help neutralize stomach acid and provide quick relief from heartburn and indigestion.\n",
      "2. **Histamine-2 (H2) blockers**:\n",
      "\t* Ranitidine (Zantac)\n",
      "\t* Famotidine (Pepcid)\n",
      "\t* These medications can help reduce acid production in the stomach and alleviate symptoms of heartburn and indigestion.\n",
      "3. **Proton pump inhibitors (PPIs)**:\n",
      "\t* Omeprazole (Prilosec)\n",
      "\t* Lansoprazole (Prevacid)\n",
      "\t* These medications can help block the production of stomach acid and provide longer-term relief from heartburn and indigestion.\n",
      "4. **Anti-diarrheal medications**:\n",
      "\t* Loperamide (Imodium)\n",
      "\t* Bismuth subsalicylate (Pepto-Bismol)\n",
      "\t* These medications can help slow down bowel movements and alleviate symptoms of diarrhea.\n",
      "5. **Pain relievers**:\n",
      "\t* Acetaminophen (Tylenol)\n",
      "\t* Ibuprofen (Advil, Motrin)\n",
      "\t* These medications can help alleviate stomach pain and discomfort, but be sure to follow the recommended dosage and consult a healthcare professional if you have any underlying medical conditions.\n",
      "\n",
      "Remember to always read and follow the label instructions, and consult a healthcare professional if:\n",
      "\n",
      "* Your symptoms persist or worsen\n",
      "* You experience severe abdominal pain, vomiting, or bleeding\n",
      "* You have a history of stomach ulcers, kidney disease, or other underlying medical conditions\n",
      "* You are taking prescription medications or have allergies\n",
      "\n",
      "Please consult a healthcare professional for a proper diagnosis and treatment plan.\n"
     ]
    }
   ],
   "source": [
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abfeb887-9df6-43db-9846-ad5ee2ebfffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-0.5.20-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from chromadb) (2.10.1)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-win_amd64.whl.metadata (262 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb)\n",
      "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from chromadb) (1.26.4)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.7.2-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from chromadb) (4.12.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.20.1-cp310-cp310-win_amd64.whl.metadata (4.7 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.28.2-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.28.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from chromadb) (0.20.0)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from chromadb) (4.66.5)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from chromadb) (1.66.1)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.2.1-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Downloading typer-0.13.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from chromadb) (8.5.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from chromadb) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.0.1-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from chromadb) (3.10.12)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from chromadb) (0.27.2)\n",
      "Collecting rich>=10.11.0 (from chromadb)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from build>=1.0.3->chromadb) (24.1)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: tomli>=1.1.0 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
      "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.6.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.35.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (3.19.6)\n",
      "Requirement already satisfied: sympy in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading Deprecated-1.2.15-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting importlib-metadata<=8.5.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.28.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-util-http==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from opentelemetry-instrumentation==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.27.1)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.25.1)\n",
      "Collecting click>=8.0.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp310-cp310-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.0.0-cp310-none-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-14.1-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.9.0)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.3.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\pavan\\anaconda\\envs\\llm_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Downloading chromadb-0.5.20-py3-none-any.whl (617 kB)\n",
      "   ---------------------------------------- 0.0/617.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 617.9/617.9 kB 5.6 MB/s eta 0:00:00\n",
      "Downloading chroma_hnswlib-0.7.6-cp310-cp310-win_amd64.whl (150 kB)\n",
      "Downloading bcrypt-4.2.1-cp39-abi3-win_amd64.whl (153 kB)\n",
      "Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
      "Downloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.9/1.9 MB 14.5 MB/s eta 0:00:00\n",
      "Downloading mmh3-5.0.1-cp310-cp310-win_amd64.whl (39 kB)\n",
      "Downloading onnxruntime-1.20.1-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 5.8/11.3 MB 27.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.3 MB 26.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 23.6 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_api-1.28.2-py3-none-any.whl (64 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.28.2-py3-none-any.whl (55 kB)\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl (12 kB)\n",
      "Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl (30 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl (159 kB)\n",
      "Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl (6.9 kB)\n",
      "Downloading opentelemetry_sdk-1.28.2-py3-none-any.whl (118 kB)\n",
      "Downloading posthog-3.7.2-py2.py3-none-any.whl (54 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading typer-0.13.1-py3-none-any.whl (44 kB)\n",
      "Downloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
      "Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading Deprecated-1.2.15-py2.py3-none-any.whl (9.9 kB)\n",
      "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "Downloading httptools-0.6.4-cp310-cp310-win_amd64.whl (88 kB)\n",
      "Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "Downloading watchfiles-1.0.0-cp310-none-win_amd64.whl (285 kB)\n",
      "Downloading websockets-14.1-cp310-cp310-win_amd64.whl (163 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53834 sha256=5868839b37c38be5bc691f1ee8ef74c02d3abb90a4a5279faa2378ada70e3c6c\n",
      "  Stored in directory: c:\\users\\pavan\\appdata\\local\\pip\\cache\\wheels\\e1\\26\\51\\d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, monotonic, durationpy, zipp, websockets, shellingham, python-dotenv, pyreadline3, pyproject_hooks, protobuf, opentelemetry-util-http, mmh3, mdurl, importlib-resources, httptools, deprecated, click, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, posthog, opentelemetry-proto, markdown-it-py, importlib-metadata, humanfriendly, googleapis-common-protos, build, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, kubernetes, fastapi, coloredlogs, typer, opentelemetry-semantic-conventions, onnxruntime, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.20 click-8.1.7 coloredlogs-15.0.1 deprecated-1.2.15 durationpy-0.9 fastapi-0.115.5 googleapis-common-protos-1.66.0 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.5.0 importlib-resources-6.4.5 kubernetes-31.0.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-5.0.1 monotonic-1.6 onnxruntime-1.20.1 opentelemetry-api-1.28.2 opentelemetry-exporter-otlp-proto-common-1.28.2 opentelemetry-exporter-otlp-proto-grpc-1.28.2 opentelemetry-instrumentation-0.49b2 opentelemetry-instrumentation-asgi-0.49b2 opentelemetry-instrumentation-fastapi-0.49b2 opentelemetry-proto-1.28.2 opentelemetry-sdk-1.28.2 opentelemetry-semantic-conventions-0.49b2 opentelemetry-util-http-0.49b2 posthog-3.7.2 protobuf-5.28.3 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 python-dotenv-1.0.1 rich-13.9.4 shellingham-1.5.4 starlette-0.41.3 typer-0.13.1 uvicorn-0.32.1 watchfiles-1.0.0 websockets-14.1 zipp-3.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script dotenv.exe is installed in 'C:\\Users\\pavan\\anaconda\\envs\\llm_env\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script watchfiles.exe is installed in 'C:\\Users\\pavan\\anaconda\\envs\\llm_env\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script uvicorn.exe is installed in 'C:\\Users\\pavan\\anaconda\\envs\\llm_env\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown-it.exe is installed in 'C:\\Users\\pavan\\anaconda\\envs\\llm_env\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script humanfriendly.exe is installed in 'C:\\Users\\pavan\\anaconda\\envs\\llm_env\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script pyproject-build.exe is installed in 'C:\\Users\\pavan\\anaconda\\envs\\llm_env\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script fastapi.exe is installed in 'C:\\Users\\pavan\\anaconda\\envs\\llm_env\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script coloredlogs.exe is installed in 'C:\\Users\\pavan\\anaconda\\envs\\llm_env\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script typer.exe is installed in 'C:\\Users\\pavan\\anaconda\\envs\\llm_env\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script onnxruntime_test.exe is installed in 'C:\\Users\\pavan\\anaconda\\envs\\llm_env\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts opentelemetry-bootstrap.exe and opentelemetry-instrument.exe are installed in 'C:\\Users\\pavan\\anaconda\\envs\\llm_env\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script chroma.exe is installed in 'C:\\Users\\pavan\\anaconda\\envs\\llm_env\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 5.28.3 which is incompatible.\n",
      "tensorflow-intel 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 5.28.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install chromadb                # database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9546f7fa-cb40-4a13-a5a1-8135a8da5ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb                                    # store data in database in form of vectors(embedding) and associated metadata format\n",
    "chroma_client = chromadb.Client()                  # 1) create client instance , 2) in cromadb we have store unstructured type of data (text , images , audio ,video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fc60a59a-709e-47fb-ab84-d74cbbc50ca9",
   "metadata": {},
   "outputs": [
    {
     "ename": "UniqueConstraintError",
     "evalue": "Collection my_collection already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUniqueConstraintError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[127], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m collection \u001b[38;5;241m=\u001b[39m \u001b[43mchroma_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy_collection\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda\\envs\\llm_env\\lib\\site-packages\\chromadb\\api\\client.py:147\u001b[0m, in \u001b[0;36mClient.create_collection\u001b[1;34m(self, name, configuration, metadata, embedding_function, data_loader, get_or_create)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_collection\u001b[39m(\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    145\u001b[0m     get_or_create: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    146\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Collection:\n\u001b[1;32m--> 147\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_server\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Collection(\n\u001b[0;32m    156\u001b[0m         client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server,\n\u001b[0;32m    157\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    158\u001b[0m         embedding_function\u001b[38;5;241m=\u001b[39membedding_function,\n\u001b[0;32m    159\u001b[0m         data_loader\u001b[38;5;241m=\u001b[39mdata_loader,\n\u001b[0;32m    160\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda\\envs\\llm_env\\lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:150\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda\\envs\\llm_env\\lib\\site-packages\\chromadb\\api\\segment.py:103\u001b[0m, in \u001b[0;36mrate_limit.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rate_limit_enforcer\u001b[38;5;241m.\u001b[39mrate_limit(func)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda\\envs\\llm_env\\lib\\site-packages\\chromadb\\rate_limit\\simple_rate_limit\\__init__.py:23\u001b[0m, in \u001b[0;36mSimpleRateLimitEnforcer.rate_limit.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda\\envs\\llm_env\\lib\\site-packages\\chromadb\\api\\segment.py:226\u001b[0m, in \u001b[0;36mSegmentAPI.create_collection\u001b[1;34m(self, name, configuration, metadata, get_or_create, tenant, database)\u001b[0m\n\u001b[0;32m    213\u001b[0m model \u001b[38;5;241m=\u001b[39m CollectionModel(\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m,\n\u001b[0;32m    215\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    222\u001b[0m     dimension\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    223\u001b[0m )\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# TODO: Let sysdb create the collection directly from the model\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m coll, created \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sysdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_configuration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43msegments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Passing empty till backend changes are deployed.\u001b[39;49;00m\n\u001b[0;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# This is lazily populated on the first add\u001b[39;49;00m\n\u001b[0;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created:\n\u001b[0;32m    239\u001b[0m     segments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39mprepare_segments_for_new_collection(coll)\n",
      "File \u001b[1;32m~\\anaconda\\envs\\llm_env\\lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:150\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda\\envs\\llm_env\\lib\\site-packages\\chromadb\\db\\mixins\\sysdb.py:241\u001b[0m, in \u001b[0;36mSqlSysDB.create_collection\u001b[1;34m(self, id, name, configuration, segments, metadata, dimension, get_or_create, tenant, database)\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    235\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_collections(\n\u001b[0;32m    236\u001b[0m                 \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mcollection\u001b[38;5;241m.\u001b[39mid, tenant\u001b[38;5;241m=\u001b[39mtenant, database\u001b[38;5;241m=\u001b[39mdatabase\n\u001b[0;32m    237\u001b[0m             )[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    238\u001b[0m             \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    239\u001b[0m         )\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 241\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m UniqueConstraintError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollection \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    243\u001b[0m collection \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m,\n\u001b[0;32m    245\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    251\u001b[0m     version\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    252\u001b[0m )\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtx() \u001b[38;5;28;01mas\u001b[39;00m cur:\n",
      "\u001b[1;31mUniqueConstraintError\u001b[0m: Collection my_collection already exists"
     ]
    }
   ],
   "source": [
    "collection = chroma_client.create_collection(name=\"my_collection\")      # create table in cromadb\n",
    "                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a20056dc-9a97-48fa-a5bc-8656c9faa231",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insert of existing embedding ID: id1\n",
      "Insert of existing embedding ID: id2\n",
      "Insert of existing embedding ID: id3\n",
      "Insert of existing embedding ID: id4\n",
      "Add of existing embedding ID: id1\n",
      "Add of existing embedding ID: id2\n",
      "Add of existing embedding ID: id3\n",
      "Add of existing embedding ID: id4\n"
     ]
    }
   ],
   "source": [
    "# add data into table \n",
    "\n",
    "collection.add(\n",
    "    documents=[\n",
    "        \"I'm yashraj kadam , I completed a Bachelor of Engineering in Computer Science, skilled in Python, SQL, and data visualization. Experienced in data analysis, machine learning, NLP, and Large Language Models (LLMs). Proficient in tools like Power BI and LangChain, with a focus on solving business problems and delivering actionable insights.\",\n",
    "        \"I am Sahil , expertize in deep learning , machine learning , nlp , and AWS cloud and 2 years of experience\",\n",
    "        \"I am raj , I have reliable in electronic and telecommunications ,ETL , file handling , cloud , python , sql like things with 5 years of experience\",\n",
    "        \"my name is shubham , i have experience in deep learning , advance java, core java , html , css ,javascript but i have no any type of experience \"\n",
    "    ],\n",
    "    ids=[\"id1\", \"id2\",\"id3\",\"id4\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f866b3b5-9463-4e81-84f3-e068451df8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['id3', 'raj']], 'embeddings': None, 'documents': [['I am raj , I have reliable in electronic and telecommunications ,ETL , file handling , cloud , python , sql like things with 5 years of experience', 'I am raj , I have reliable in electronic and telecommunications ,ETL , file handling , cloud , python , sql like things with 5 years of experience']], 'uris': None, 'data': None, 'metadatas': [[None, None]], 'distances': [[0.7995156049728394, 0.7995156049728394]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
     ]
    }
   ],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[\"I want python developer with atleast 1 years of experience\"], # Chroma will embed this for you\n",
    "    n_results=2 # how many results to return\n",
    ")\n",
    "print(results)                       # this happens bcz we have multiple times add the data in form id's and names(yashraj,sahil,raj,shubham) like that\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8b53b8f4-610b-4c56-b8fa-e97db0cbc315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['id2', 'sahil']], 'embeddings': None, 'documents': [['I am Sahil , expertize in deep learning , machine learning , nlp , and AWS cloud and 2 years of experience', 'I am Sahil , expertize in deep learning , machine learning , nlp , and AWS cloud and 2 years of experience']], 'uris': None, 'data': None, 'metadatas': [[None, None]], 'distances': [[0.7562498450279236, 0.7562498450279236]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
     ]
    }
   ],
   "source": [
    "results1 = collection.query(\n",
    "    query_texts=[\"I want machine learning developer with atleast 1 years of experience\"], # Chroma will embed this for you\n",
    "    n_results=2 # how many results to return\n",
    ")\n",
    "print(results1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0e21cfca-cf0b-4360-a3dd-440298bdd5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['id2', 'sahil']], 'embeddings': None, 'documents': [['I am Sahil , expertize in deep learning , machine learning , nlp , and AWS cloud and 2 years of experience', 'I am Sahil , expertize in deep learning , machine learning , nlp , and AWS cloud and 2 years of experience']], 'uris': None, 'data': None, 'metadatas': [[None, None]], 'distances': [[0.46505510807037354, 0.46505510807037354]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
     ]
    }
   ],
   "source": [
    "results2 = collection.query(\n",
    "    query_texts=[\"I want machine learning developer with experties in llm and AWS cloud 1 years of experience\"], # Chroma will embed this for you\n",
    "    n_results=2 # how many results to return\n",
    ")\n",
    "print(results2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156ccc47-0703-4e15-8ff3-d846cbb58598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd9356c-4407-4f90-b7ab-da7e877552ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d39a855-1915-4da1-ac49-7188a33f44db",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_post=\"\"\"\n",
    "must-Have\n",
    "Experience in Python, Pandas, Numpy.\n",
    "Experience in NLP Techniques.\n",
    "Experience in RASA or any other conversational framework.\n",
    "Text Processing Techniques- NLTK, Text Embeddings etc.\n",
    "Exposure in deploying ML models in Cloud , Exposure to Docker Containers and Kubernetes,Understanding of MLOps\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7881d851-69bd-4c5a-a58a-00ae3e2b33de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the job post, here are the extracted details:\n",
      "\n",
      "1. **Experience in field**: \n",
      "   - Python\n",
      "   - NLP (Natural Language Processing)\n",
      "   - Conversational framework (specifically RASA)\n",
      "   - Text Processing\n",
      "   - Machine Learning (ML)\n",
      "   - Cloud deployment\n",
      "   - MLOps\n",
      "\n",
      "2. **Skills**:\n",
      "   - Python\n",
      "   - Pandas\n",
      "   - Numpy\n",
      "   - NLP Techniques\n",
      "   - RASA (or other conversational framework)\n",
      "   - NLTK (Natural Language Toolkit)\n",
      "   - Text Embeddings\n",
      "   - Docker Containers\n",
      "   - Kubernetes\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate       # define the structure of a conversation between system (AI assistent) and human user\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You have to extract following details from job post , details are experience in which field , skills .\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "result=chain.invoke(\n",
    "    {\n",
    "        \"input\": job_post,\n",
    "        \n",
    "    }\n",
    ")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2ade31-a39a-4bfe-9e94-aaacd7bd5c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bf4f1d98-a469-449e-9d7e-d5d9a55337ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_post_second=\"\"\"\n",
    "Data Analyst/Data Scientist with a Bachelor of Engineering in Computer Science, skilled in Python, SQL, and data visualization.\n",
    "Experienced in data analysis, machine learning, NLP, and Large Language Models (LLMs). \n",
    "Proficient in tools like Power BI and LangChain, with a focus on solving business problems and delivering actionable insights.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2795d949-c299-4e31-9a94-1760884a03af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"experience\": {\n",
      "    \"field\": \"Data Analysis, Machine Learning, NLP, LLMs\"\n",
      "  },\n",
      "  \"skills\": {\n",
      "    \"programming_languages\": [\"Python\"],\n",
      "    \"databases\": [\"SQL\"],\n",
      "    \"tools\": [\"Power BI\", \"LangChain\"],\n",
      "    \"technologies\": [\"Data Visualization\", \"Machine Learning\", \"NLP\", \"Large Language Models (LLMs)\"]\n",
      "  }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You have to extract following details from job post , details are experience in which field , skills . in json format also with specific format and dont give wested information\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "result=chain.invoke(\n",
    "    {\n",
    "        \"input\": job_post_second,\n",
    "        \n",
    "    }\n",
    ")\n",
    "\n",
    "print(result.content)                     # here in output ```----``` where ```are part of data not behave like a string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8d1fec9a-f04c-4735-b183-26b9f8436286",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda\\envs\\llm_env\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32m~\\anaconda\\envs\\llm_env\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32m~\\anaconda\\envs\\llm_env\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "json.loads(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6928ca42-6fc7-42a5-ad72-becd29a73eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"experience\": {\n",
      "    \"field\": \"Data Analysis, Machine Learning, NLP, LLMs\"\n",
      "  },\n",
      "  \"skills\": {\n",
      "    \"programming_languages\": [\"Python\"],\n",
      "    \"databases\": [\"SQL\"],\n",
      "    \"tools\": [\"Power BI\", \"LangChain\"],\n",
      "    \"technologies\": [\"Data Visualization\", \"Machine Learning\", \"NLP\", \"Large Language Models (LLMs)\"]\n",
      "  }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "520e51e1-90dd-454b-9de4-bd977eea32e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"experience\": {\\n    \"field\": \"Data Analysis, Machine Learning, NLP, LLMs\"\\n  },\\n  \"skills\": {\\n    \"programming_languages\": [\"Python\"],\\n    \"databases\": [\"SQL\"],\\n    \"tools\": [\"Power BI\", \"LangChain\"],\\n    \"technologies\": [\"Data Visualization\", \"Machine Learning\", \"NLP\", \"Large Language Models (LLMs)\"]\\n  }\\n}\\n```'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f708871c-f952-4532-b92d-90d8eb9dad2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'json\\n{\\n  \"experience\": {\\n    \"field\": \"Data Analysis, Machine Learning, NLP, LLMs\"\\n  },\\n  \"skills\": {\\n    \"programming_languages\": [\"Python\"],\\n    \"databases\": [\"SQL\"],\\n    \"tools\": [\"Power BI\", \"LangChain\"],\\n    \"technologies\": [\"Data Visualization\", \"Machine Learning\", \"NLP\", \"Large Language Models (LLMs)\"]\\n  }\\n}'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=result.content.strip(\"`\\n\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "34be7e70-9888-41d9-8a79-12d16a868454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"experience\": {\\n    \"field\": \"Data Analysis, Machine Learning, NLP, LLMs\"\\n  },\\n  \"skills\": {\\n    \"programming_languages\": [\"Python\"],\\n    \"databases\": [\"SQL\"],\\n    \"tools\": [\"Power BI\", \"LangChain\"],\\n    \"technologies\": [\"Data Visualization\", \"Machine Learning\", \"NLP\", \"Large Language Models (LLMs)\"]\\n  }\\n}'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=a.strip(\"json\\n\")\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3232ed5e-524d-4af1-bb2d-c5bcc181fad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experience': {'field': 'Data Analysis, Machine Learning, NLP, LLMs'},\n",
       " 'skills': {'programming_languages': ['Python'],\n",
       "  'databases': ['SQL'],\n",
       "  'tools': ['Power BI', 'LangChain'],\n",
       "  'technologies': ['Data Visualization',\n",
       "   'Machine Learning',\n",
       "   'NLP',\n",
       "   'Large Language Models (LLMs)']}}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details=json.loads(b)\n",
    "details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fa54aafd-df37-4f21-b02d-b1c70b65a82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'programming_languages': ['Python'], 'databases': ['SQL'], 'tools': ['Power BI', 'LangChain'], 'technologies': ['Data Visualization', 'Machine Learning', 'NLP', 'Large Language Models (LLMs)']}\n"
     ]
    }
   ],
   "source": [
    "print(details[\"skills\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e00e7375-f34b-4983-964a-cc3e145b455f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Visualization , Machine Learning , NLP , Large Language Models (LLMs)'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills = \" , \".join(details[\"skills\"][\"technologies\"])\n",
    "skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6ff8002d-9e05-4c6f-92fe-d4f8c5f1345b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['id1', 'yashraj']], 'embeddings': None, 'documents': [[\"I'm yashraj kadam , I completed a Bachelor of Engineering in Computer Science, skilled in Python, SQL, and data visualization. Experienced in data analysis, machine learning, NLP, and Large Language Models (LLMs). Proficient in tools like Power BI and LangChain, with a focus on solving business problems and delivering actionable insights.\", \"I'm yashraj kadam , I completed a Bachelor of Engineering in Computer Science, skilled in Python, SQL, and data visualization. Experienced in data analysis, machine learning, NLP, and Large Language Models (LLMs). Proficient in tools like Power BI and LangChain, with a focus on solving business problems and delivering actionable insights.\"]], 'uris': None, 'data': None, 'metadatas': [[None, None]], 'distances': [[1.1136071681976318, 1.1136071681976318]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
     ]
    }
   ],
   "source": [
    "results1 = collection.query(\n",
    "    query_texts=[skills], # Chroma will embed this for you\n",
    "    n_results=2 # how many results to return\n",
    ")\n",
    "print(results1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3ec589ba-8192-40c6-afce-b624cc45c6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'm yashraj kadam , I completed a Bachelor of Engineering in Computer Science, skilled in Python, SQL, and data visualization. Experienced in data analysis, machine learning, NLP, and Large Language Models (LLMs). Proficient in tools like Power BI and LangChain, with a focus on solving business problems and delivering actionable insights.\",\n",
       " \"I'm yashraj kadam , I completed a Bachelor of Engineering in Computer Science, skilled in Python, SQL, and data visualization. Experienced in data analysis, machine learning, NLP, and Large Language Models (LLMs). Proficient in tools like Power BI and LangChain, with a focus on solving business problems and delivering actionable insights.\"]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description=results1[\"documents\"][0]\n",
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e3e497d7-54ac-4d67-95ee-95bb665a8dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm yashraj kadam , I completed a Bachelor of Engineering in Computer Science, skilled in Python, SQL, and data visualization. Experienced in data analysis, machine learning, NLP, and Large Language Models (LLMs). Proficient in tools like Power BI and LangChain, with a focus on solving business problems and delivering actionable insights. , I'm yashraj kadam , I completed a Bachelor of Engineering in Computer Science, skilled in Python, SQL, and data visualization. Experienced in data analysis, machine learning, NLP, and Large Language Models (LLMs). Proficient in tools like Power BI and LangChain, with a focus on solving business problems and delivering actionable insights.\n"
     ]
    }
   ],
   "source": [
    "portfolio=\" , \".join(description)\n",
    "print(portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a688b4e0-33ac-4254-9caf-31d3ae9535db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Shortlisted Candidates for TCS Job Post\n",
      "\n",
      "Dear Recruitment Team at TCS,\n",
      "\n",
      "I am writing to inform you that we have shortlisted a few candidates whose portfolios match the requirements for the current job post at TCS. We believe these candidates have the necessary skills and experience to excel in this role.\n",
      "\n",
      "One of the shortlisted candidates is Yashraj Kadam, who has completed a Bachelor of Engineering in Computer Science. He is skilled in Python, SQL, and data visualization, and has experience in data analysis, machine learning, NLP, and Large Language Models (LLMs). He is also proficient in tools like Power BI and LangChain.\n",
      "\n",
      "We would like to schedule an interview with Yashraj and other shortlisted candidates to further assess their suitability for the role. Please let us know a convenient time and date for the interview.\n",
      "\n",
      "We look forward to hearing back from you and working together to find the best fit for the position.\n",
      "\n",
      "Best regards,\n",
      "Yashraj Kadam\n",
      "Placement Officer\n",
      "Codespyder Technology\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_email = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\" we are working as a placement officer in placement consultancy codespyder technology .\n",
    "            we have sortlisted candidates portfolio as per the requirment in TCS job post ,\n",
    "            create an email to recruitement team of TCS mentioning that we have best suitable candidates for this job post .\n",
    "            dont provide extra other un-necesary information.\n",
    "            \"\"\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain_email = prompt_email | llm\n",
    "result_email=chain_email.invoke(\n",
    "    {\n",
    "        \"input\": portfolio,\n",
    "        \n",
    "    }\n",
    ")\n",
    "\n",
    "print(result_email.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1a974d-deaa-430f-94e7-b84a88c4ea57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm env",
   "language": "python",
   "name": "llm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
